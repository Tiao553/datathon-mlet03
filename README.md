# Datathon Machine Learning Engineering

[![Assista √† apresenta√ß√£o no YouTube](https://img.shields.io/badge/YouTube-Apresenta√ß√£o-red?logo=youtube)](https://youtu.be/v03U9tBDizg)
[![Phase](https://img.shields.io/badge/Phase-2%20Complete-green)]()
[![Airflow](https://img.shields.io/badge/Airflow-2.8.0-blue)]()
[![Evidently](https://img.shields.io/badge/Evidently-0.4.30-orange)]()

Clique no badge acima ou no link abaixo para assistir √† apresenta√ß√£o do projeto:

üîó [Apresenta√ß√£o no YouTube](https://youtu.be/v03U9tBDizg)

---

## üìã √çndice

- [Contexto](#contexto)
- [Desafios da Empresa](#desafios-da-empresa)
- [Objetivo do Projeto](#objetivo-do-projeto)
- [Solu√ß√£o Proposta](#solu√ß√£o-proposta)
- [Arquitetura](#-arquitetura)
- [Quick Start](#-quick-start)
- [Servi√ßos & URLs](#-servi√ßos--urls)
- [Documenta√ß√£o](#-documenta√ß√£o)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [MLOps Stack](#-mlops-stack)
- [Roadmap](#-roadmap)
- [Como Executar](#como-executar)
- [Monitoramento e Testes](#monitoramento-e-testes)

---

## Contexto

Este projeto foi desenvolvido como parte do **Datathon P√≥s Tech**, com o objetivo de aplicar Intelig√™ncia Artificial para solucionar desafios reais de uma empresa do setor de bodyshop e recrutamento, a **Decision**. A empresa busca otimizar o processo de recrutamento e sele√ß√£o, conectando talentos qualificados √†s necessidades dos clientes, principalmente no setor de TI, onde agilidade e precis√£o no "match" entre candidatos(as) e vagas s√£o essenciais.

O projeto evoluiu de um **prot√≥tipo inicial** para uma **plataforma MLOps avan√ßada** com monitoramento de drift, orquestra√ß√£o de pipelines e gest√£o de prompts LLM.

## Desafios da Empresa

- ‚ùå Falta de padroniza√ß√£o em entrevistas, gerando perda de informa√ß√µes valiosas
- ‚ùå Dificuldade em identificar o real engajamento dos candidatos(as)
- ‚ùå Necessidade de alinhar habilidades t√©cnicas, fit cultural e motiva√ß√£o dos candidatos(as) √†s vagas
- ‚ùå Processo manual e pouco escal√°vel para encontrar o(a) candidato(a) ideal em tempo h√°bil

## Objetivo do Projeto

Desenvolver uma solu√ß√£o baseada em IA para automatizar e aprimorar o processo de recrutamento, propondo algoritmos e ferramentas que:

- ‚úÖ Padronizem e otimizem entrevistas
- ‚úÖ Identifiquem padr√µes de candidatos(as) de sucesso
- ‚úÖ Realizem o "match" entre perfis e vagas de forma eficiente e baseada em dados
- ‚úÖ Disponibilizem o modelo de forma produtiva via API
- ‚úÖ Monitorem drift e degrada√ß√£o do modelo automaticamente
- ‚úÖ Gerenciem prompts LLM com versionamento

## Solu√ß√£o Proposta

A solu√ß√£o contempla uma **plataforma MLOps completa** com:

### Core ML Pipeline

- **Pipeline completo de Machine Learning**: feature engineering, pr√©-processamento, treinamento, valida√ß√£o e salvamento do modelo
- **Ensemble de modelos**: Skills Scorer, Cultural Scorer, Behavioral Scorer
- **LLM-based extraction**: An√°lise de curr√≠culos e descri√ß√µes de vagas usando Ollama/DeepSeek

### Deployment & Serving

- **API FastAPI**: endpoint `/predict` para scoring de candidatos
- **Docker Compose**: stack completo com 9+ servi√ßos
- **LLM Adapter Pattern**: Suporte para LLMs locais (Ollama) e cloud (DeepSeek)

### MLOps & Observability

- **Apache Airflow**: Orquestra√ß√£o de DAGs para drift monitoring
- **Evidently AI**: Detec√ß√£o autom√°tica de drift de dados
- **MLflow**: Tracking de experimentos e modelos
- **ELK Stack**: Logs centralizados (Elasticsearch, Logstash, Kibana)
- **Langfuse**: Gest√£o de prompts LLM (configurado, integra√ß√£o pendente)

### Exemplos de Casos de Uso

- Agente de IA para entrevistas automatizadas, utilizando dados hist√≥ricos para simular o papel do entrevistador
- Otimiza√ß√£o do processo de entrevistas, aprendendo padr√µes de sucesso em candidatos(as) anteriores
- Identifica√ß√£o de atributos-chave em candidatos(as) de sucesso via algoritmos de clusteriza√ß√£o
- **Monitoramento semanal de drift** para detectar degrada√ß√£o do modelo
- **Scoring autom√°tico** de candidatos via API REST

---

## üèóÔ∏è Arquitetura

### Diagrama da Solu√ß√£o - Cen√°rio 0 (Fase 2 - Desenvolvimento Local)

```mermaid
graph LR
    A[Client] -->|HTTP| B[FastAPI API]
    B -->|Extract Features| C[LLM Gateway]
    C -->|Local Dev| D[Ollama]
    C -->|Production| E[DeepSeek API]
    B -->|Score| F[Skills Scorer]
    B -->|Score| G[Cultural Scorer]
    B -->|Score| H[Behavioral Scorer]
    B -->|Track| I[MLflow]
    B -->|Log| J[Logstash]
    J --> K[Elasticsearch]
    K --> L[Kibana]
    M[Airflow Scheduler] -->|Weekly| N[Drift Detection DAG]
    N -->|Evidently AI| O[HTML Reports]
    P[Langfuse DB] -->|Future| C
```

### Decis√µes Arquiteturais

Consulte **[ADR-0: Architecture Evolution](docs/ADR-0.md)** para detalhes sobre:

- ‚úÖ **Fase 1**: LLM Adapter Pattern (Decoupling) - **COMPLETA**
- ‚úÖ **Fase 2**: Drift Monitoring (Airflow + Evidently) - **COMPLETA**
- üîú **Fase 3**: Immutable Payload (Zero-Shot Learning) - **PLANEJADA**

---

---

## ‚ö†Ô∏è Depend√™ncias Cr√≠ticas

> [!IMPORTANT]
> **Cadastro de Vagas (job_id)**: Para o correto funcionamento do scoring, √© **imprescind√≠vel** que os `job_id`s consultados estejam previamente cadastrados e processados na base de dados (Feature Store).
>
> **Retreino de Modelos**: A performance do modelo depende da atualiza√ß√£o constante dos dados. √â **necess√°rio** que o DAG de retreino (`weekly_retraining`) seja executado semanalmente para incorporar novas vagas e perfis ao espa√ßo vetorial e aos modelos comportamentais.

## üöÄ Quick Start

### Pr√©-requisitos

- Docker & Docker Compose
- **GPU NVIDIA GTX 4060** (ou superior) para rodar Ollama local OU chave API DeepSeek
- 8GB+ RAM (16GB recomendado para Ollama local)
- Ollama instalado localmente (se usar LLM local)

### 1. Clone e Configure

```bash
git clone https://github.com/seu-usuario/datathon-mlet03.git
cd datathon-mlet03

# Configure vari√°veis de ambiente
cp .env.example .env
# Edite .env para definir LLM_PROVIDER (ollama ou deepseek)
```

### 2. Inicie os Servi√ßos

```bash
cd infrastructure/local
docker-compose up -d
```

**Aguarde ~2 minutos para todos os servi√ßos inicializarem.**

### 3. Verifique os Servi√ßos

```bash
docker-compose ps
```

Todos os servi√ßos devem mostrar status `Up`.

### 4. Teste a API

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "resume_text": "Desenvolvedor Python com 5 anos de experi√™ncia em FastAPI e Docker",
    "job_description": "Vaga para desenvolvedor backend Python s√™nior"
  }'
```

---

## üåê Servi√ßos & URLs

### Servi√ßos de Produ√ß√£o

| Servi√ßo | Porta | URL | Credenciais | Descri√ß√£o |
|---------|-------|-----|-------------|-----------|
| **API** | 8000 | <http://localhost:8000> | - | Endpoint de scoring |
| **MLflow** | 5000 | <http://localhost:5000> | - | Tracking de experimentos |
| **Kibana** | 5601 | <http://localhost:5601> | - | Visualiza√ß√£o de logs |
| **Elasticsearch** | 9200 | <http://localhost:9200> | - | Armazenamento de logs |

### Servi√ßos MLOps

| Servi√ßo | Porta | URL | Credenciais | Descri√ß√£o |
|---------|-------|-----|-------------|-----------|
| **Airflow** | 8080 | <http://localhost:8080> | admin / admin | UI de gerenciamento de DAGs |
| **Langfuse** | 3000 | <http://localhost:3000> | (setup necess√°rio) | Gest√£o de prompts LLM |

---

## üìö Documenta√ß√£o

### Documenta√ß√£o Principal

| Documento | Descri√ß√£o | Link |
|-----------|-----------|------|
| **ADR-0** | Decis√µes arquiteturais e roadmap | [docs/ADR-0.md](docs/ADR-0.md) |
| **API Reference** | Documenta√ß√£o dos endpoints | [docs/api_reference.md](docs/api_reference.md) |
| **Data Architecture** | Padr√£o Medallion, gest√£o de PII | [docs/data_architecture.md](docs/data_architecture.md) |
| **Feature Engineering** | An√°lise de features e pipeline | [docs/feature_engineering_analysis.md](docs/feature_engineering_analysis.md) |

### Decis√µes T√©cnicas

| Documento | Descri√ß√£o | Link |
|-----------|-----------|------|
| **Model Decisions** | Escolha e justificativa dos modelos | [docs/model_decisions.md](docs/model_decisions.md) |
| **Technical Decisions** | Decis√µes de stack tecnol√≥gico | [docs/technical_decisions.md](docs/technical_decisions.md) |
| **Drift Detection Tools** | Compara√ß√£o: Evidently vs Deepchecks vs Whylogs | [docs/drift_detection_tools.md](docs/drift_detection_tools.md) |

### Resultados de Experimentos

| Documento | Descri√ß√£o | Link |
|-----------|-----------|------|
| **Experiment Summary** | M√©tricas de performance dos modelos | [docs/experiment_summary.md](docs/experiment_summary.md) |
| **Pipeline Health** | Qualidade de dados e relat√≥rios de drift | [docs/experiment_results_and_pipeline_health.md](docs/experiment_results_and_pipeline_health.md) |

### Infraestrutura

| Documento | Descri√ß√£o | Link |
|-----------|-----------|------|
| **Infrastructure README** | Setup local vs cloud | [infrastructure/README.md](infrastructure/README.md) |
| **DAGs README** | Documenta√ß√£o das DAGs do Airflow | [dags/README.md](dags/README.md) |

---

## üìÅ Estrutura do Projeto

```
datathon-mlet03/
‚îú‚îÄ‚îÄ infrastructure/          # Configura√ß√µes de deployment
‚îÇ   ‚îú‚îÄ‚îÄ local/              # Stack Docker Compose
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml    # Todos os servi√ßos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile            # API service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.airflow    # Airflow customizado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements-airflow.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/               # Configs do Logstash
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ airflow/              # Logs e plugins
‚îÇ   ‚îî‚îÄ‚îÄ cloud/              # Terraform (futuro)
‚îÇ
‚îú‚îÄ‚îÄ dags/                   # DAGs do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ drift_monitoring.py       # Drift check semanal
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ drift_detection.py    # Helpers do Evidently
‚îÇ
‚îú‚îÄ‚îÄ data_pipeline/          # Pipeline de ML
‚îÇ   ‚îú‚îÄ‚îÄ pipe/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ features/       # Feature engineering
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scoring/        # Modelos de scoring
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ training/       # Treinamento
‚îÇ   ‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_gateway.py  # LLM Adapter Pattern
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ serving/                # API
‚îÇ   ‚îî‚îÄ‚îÄ api.py             # Aplica√ß√£o FastAPI
‚îÇ
‚îú‚îÄ‚îÄ models/                 # Modelos treinados
‚îÇ   ‚îî‚îÄ‚îÄ artifacts/
‚îÇ
‚îú‚îÄ‚îÄ data/                   # Datasets
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ bronze/
‚îÇ   ‚îú‚îÄ‚îÄ silver/
‚îÇ   ‚îî‚îÄ‚îÄ curated/
‚îÇ
‚îú‚îÄ‚îÄ docs/                   # Documenta√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ ADR-0.md           # Decis√µes arquiteturais
‚îÇ   ‚îú‚îÄ‚îÄ api_reference.md
‚îÇ   ‚îú‚îÄ‚îÄ data_architecture.md
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ monitoring/             # Logs e m√©tricas
‚îÇ
‚îú‚îÄ‚îÄ .env                    # Configura√ß√£o de ambiente
‚îî‚îÄ‚îÄ README.md              # Este arquivo
```

---

## Tecnologias Utilizadas

### Core ML Stack

- Python 3.10
- Pandas, NumPy, Polars
- Scikit-learn, LightGBM
- Sentence Transformers

### LLM & AI

- Ollama (local)
- DeepSeek API (cloud)
- OpenAI SDK

### API & Serving

- FastAPI
- Uvicorn
- Pydantic

### MLOps & Observability

- **Apache Airflow** 2.8.0 - Orquestra√ß√£o
- **Evidently AI** 0.4.30 - Drift detection
- **MLflow** 2.8.1 - Experiment tracking
- **Langfuse** - Prompt management
- **Elasticsearch** 7.17.13 - Log storage
- **Logstash** 7.17.13 - Log ingestion
- **Kibana** 7.17.13 - Log visualization

### Infrastructure

- Docker & Docker Compose
- PostgreSQL (Airflow, Langfuse)

---

## üõ†Ô∏è MLOps Stack

### Fase 1: LLM Adapter Pattern ‚úÖ

**Problema:** Depend√™ncia hardcoded do Ollama local  
**Solu√ß√£o:** Adapter Pattern com interface `LLMProvider`

**Arquivos:**

- `data_pipeline/infra/llm_gateway.py`
- `data_pipeline/pipe/features/prompts.py`

**Uso:**

```python
from data_pipeline.infra.llm_gateway import get_llm_provider

provider = get_llm_provider()  # Auto-seleciona baseado no .env
response = provider.generate(prompt)
```

### Fase 2: Drift Monitoring ‚úÖ

**Ferramentas:** Apache Airflow + Evidently AI

**DAG:** `drift_monitoring_weekly`

- **Agendamento:** Todo domingo √† meia-noite
- **Tarefas:**
  1. `check_data_drift` - An√°lise com Evidently AI
  2. `check_model_performance` - Tracking de m√©tricas
  3. `generate_drift_report` - Relat√≥rio HTML + alertas

**Relat√≥rios:** Salvos em `infrastructure/local/airflow/airflow_logs/`

**Alertas:** Disparados se drift > 15%

### Fase 3: Immutable Payload üîú

**Objetivo:** Zero-shot learning para novos jobs

**Design:** Expandir payload da API de 3 para ~30 campos:

- Perfil do candidato (senioridade, educa√ß√£o, experi√™ncia)
- Skills (t√©cnicas, soft, ferramentas)
- Sinais de qualidade (completude, localidade)
- Embeddings (vetores sem√¢nticos)
- Contexto da vaga (t√≠tulo, departamento, requisitos)

**Benef√≠cio:** Sem necessidade de retreinamento para novos `job_id`

---

## üó∫Ô∏è Roadmap

### ‚úÖ Completo

- [x] Fase 1: LLM Adapter Pattern
- [x] Fase 2: Drift Monitoring (Airflow + Evidently)
- [x] API com ensemble de modelos
- [x] MLflow experiment tracking
- [x] ELK Stack para observabilidade
- [x] Deploy via Docker Compose

### üîú Em Progresso

- [ ] Integra√ß√£o Langfuse para gest√£o de prompts
- [ ] Cria√ß√£o de dataset de refer√™ncia para drift detection
- [ ] Alertas automatizados (Slack/Email)

### üìÖ Planejado (Fase 3)

- [ ] Implementa√ß√£o do Immutable Payload
- [ ] Refatora√ß√£o da API para features granulares
- [ ] Capacidade de zero-shot scoring
- [ ] Deploy em cloud com Terraform
- [ ] Pipeline CI/CD (GitHub Actions)

---

## Como Executar

### Op√ß√£o 1: Docker Compose (Recomendado)

```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/seu-usuario/datathon-mlet03.git
cd datathon-mlet03

# 2. Configure ambiente
cp .env.example .env
# Edite .env conforme necess√°rio

# 3. Inicie todos os servi√ßos
cd infrastructure/local
docker-compose up -d

# 4. Verifique os logs
docker-compose logs -f api
```

### Op√ß√£o 2: Desenvolvimento Local (sem Docker)

```bash
# 1. Crie ambiente virtual
python3 -m venv .venv
source .venv/bin/activate

# 2. Instale depend√™ncias
pip install -r data_pipeline/requirements.txt

# 3. Execute pipeline de treinamento (opcional)
python data_pipeline/main_feature_engineering.py
python data_pipeline/main_curated.py

# 4. Inicie a API
uvicorn serving.api:app --reload --host 0.0.0.0 --port 8000
```

### Testando a API

```bash
# Health check
curl http://localhost:8000/health

# Predi√ß√£o
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "resume_text": "Desenvolvedor Python com 5 anos de experi√™ncia",
    "job_description": "Vaga para desenvolvedor backend s√™nior"
  }'
```

### Acessando Airflow

1. Acesse <http://localhost:8080>
2. Login: `admin` / `admin`
3. Desative pausa na DAG `drift_monitoring_weekly`
4. Clique em "Trigger DAG" para executar manualmente

---

## Monitoramento e Testes

### Logs

- **API Logs:** `docker-compose logs api`
- **Airflow Logs:** `infrastructure/local/airflow/airflow_logs/`
- **Elasticsearch:** <http://localhost:9200>
- **Kibana:** <http://localhost:5601>

### M√©tricas

- **MLflow:** <http://localhost:5000> - Tracking de experimentos
- **Relat√≥rios de Drift:** Gerados semanalmente pelo Airflow

### Testes Unit√°rios

```bash
# Execute testes (quando dispon√≠veis)
pytest data_pipeline/tests/

# Teste de drift detection
python test_drift_detection.py
```

---

## Entreg√°veis

1. ‚úÖ C√≥digo-fonte organizado e documentado neste reposit√≥rio
2. ‚úÖ API de predi√ß√£o rodando em <http://localhost:8000>
3. ‚úÖ V√≠deo de at√© 5 minutos explicando a estrat√©gia ([link no topo](https://youtu.be/v03U9tBDizg))
4. ‚úÖ Stack MLOps completo com Airflow, MLflow, ELK
5. ‚úÖ Documenta√ß√£o t√©cnica abrangente

---

## ü§ù Contribuindo

1. Crie uma feature branch a partir da `main`
2. Fa√ßa suas altera√ß√µes
3. Atualize a documenta√ß√£o
4. Teste localmente
5. Crie um Pull Request

---

## üìÑ Licen√ßa

Este projeto foi desenvolvido para o Datathon P√≥s Tech.

---

## üìû Contato

Para d√∫vidas ou sugest√µes, entre em contato com o respons√°vel pelo projeto.

---

## üôè Agradecimentos

- **Decision** - Parceiro de neg√≥cio
- **Datathon P√≥s Tech** - Organizador do desafio
- **Evidently AI** - Ferramenta de drift detection
- **Apache Airflow** - Orquestra√ß√£o de workflows
- **Langfuse** - Gest√£o de prompts

---

**Constru√≠do com ‚ù§Ô∏è para Excel√™ncia em MLOps**
